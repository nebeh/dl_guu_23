{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a11e3c4-f336-43b0-b43d-0d5c74322092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................Training Accuracy at epoch 1 is:  0.5373134328358209\n",
      "Validation Accuracy at epoch 1 is:  0.4630541871921182\n",
      "...................................................Training Accuracy at epoch 2 is:  0.527363184079602\n",
      "Validation Accuracy at epoch 2 is:  0.5369458128078818\n",
      "...................................................Training Accuracy at epoch 3 is:  0.5422885572139303\n",
      "Validation Accuracy at epoch 3 is:  0.5369458128078818\n",
      "...................................................Training Accuracy at epoch 4 is:  0.599502487562189\n",
      "Validation Accuracy at epoch 4 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 5 is:  0.5199004975124378\n",
      "Validation Accuracy at epoch 5 is:  0.5369458128078818\n",
      "...................................................Training Accuracy at epoch 6 is:  0.5945273631840796\n",
      "Validation Accuracy at epoch 6 is:  0.5714285714285714\n",
      "...................................................Training Accuracy at epoch 7 is:  0.5572139303482587\n",
      "Validation Accuracy at epoch 7 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 8 is:  0.5796019900497512\n",
      "Validation Accuracy at epoch 8 is:  0.5369458128078818\n",
      "...................................................Training Accuracy at epoch 9 is:  0.5696517412935324\n",
      "Validation Accuracy at epoch 9 is:  0.5763546798029556\n",
      "...................................................Training Accuracy at epoch 10 is:  0.5497512437810945\n",
      "Validation Accuracy at epoch 10 is:  0.5517241379310345\n",
      "...................................................Training Accuracy at epoch 11 is:  0.5621890547263682\n",
      "Validation Accuracy at epoch 11 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 12 is:  0.5845771144278606\n",
      "Validation Accuracy at epoch 12 is:  0.5763546798029556\n",
      "...................................................Training Accuracy at epoch 13 is:  0.582089552238806\n",
      "Validation Accuracy at epoch 13 is:  0.6108374384236454\n",
      "...................................................Training Accuracy at epoch 14 is:  0.5920398009950248\n",
      "Validation Accuracy at epoch 14 is:  0.5960591133004927\n",
      "...................................................Training Accuracy at epoch 15 is:  0.6044776119402985\n",
      "Validation Accuracy at epoch 15 is:  0.5566502463054187\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "#%%\n",
    "\n",
    "train_data = datasets.ImageFolder('/home/strike/work/learn/guu/dl_guu_23/07/cats_and_dogs/training_set/training_set/', transform=train_trans)\n",
    "test_data = datasets.ImageFolder('/home/strike/work/learn/guu/dl_guu_23/07/cats_and_dogs/test_set/test_set/', transform=test_trans)\n",
    "#%%\n",
    "import numpy as np\n",
    "t = range(len(test_data))\n",
    "t = np.random.permutation(t)\n",
    "n = int(len(t)/2)\n",
    "idx_test = t[:n]\n",
    "idx_val = t[n:]\n",
    "\n",
    "val_data = Subset(test_data, idx_val)\n",
    "test_data = Subset(test_data, idx_test)\n",
    "\n",
    "\n",
    "#%%\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=8,    shuffle=True)\n",
    "    \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "    batch_size=8,    shuffle=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "    batch_size=8,    shuffle=False)\n",
    "#%%\n",
    "from vit_pytorch import ViT\n",
    "N = 224\n",
    "\n",
    "model = ViT(\n",
    "    image_size = N,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 128,\n",
    "    depth = 2,\n",
    "    heads = 4,\n",
    "    mlp_dim = 256,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e211e21-7a0d-498c-b07a-b163983f5853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab788ee1-9bf2-414a-a6d2-7204a0497093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8f15e6-4e69-4d87-9eab-57ce69e97b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................Training Accuracy at epoch 1 is:  0.572139303482587\n",
      "Validation Accuracy at epoch 1 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 2 is:  0.6268656716417911\n",
      "Validation Accuracy at epoch 2 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 3 is:  0.6119402985074627\n",
      "Validation Accuracy at epoch 3 is:  0.5665024630541872\n",
      "...................................................Training Accuracy at epoch 4 is:  0.6119402985074627\n",
      "Validation Accuracy at epoch 4 is:  0.5665024630541872\n",
      "...................................................Training Accuracy at epoch 5 is:  0.5696517412935324\n",
      "Validation Accuracy at epoch 5 is:  0.5714285714285714\n",
      "...................................................Training Accuracy at epoch 6 is:  0.6368159203980099\n",
      "Validation Accuracy at epoch 6 is:  0.5714285714285714\n",
      "...................................................Training Accuracy at epoch 7 is:  0.5895522388059702\n",
      "Validation Accuracy at epoch 7 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 8 is:  0.6119402985074627\n",
      "Validation Accuracy at epoch 8 is:  0.5369458128078818\n",
      "...................................................Training Accuracy at epoch 9 is:  0.5522388059701493\n",
      "Validation Accuracy at epoch 9 is:  0.5714285714285714\n",
      "...................................................Training Accuracy at epoch 10 is:  0.6218905472636815\n",
      "Validation Accuracy at epoch 10 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 11 is:  0.5970149253731343\n",
      "Validation Accuracy at epoch 11 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 12 is:  0.6194029850746269\n",
      "Validation Accuracy at epoch 12 is:  0.5517241379310345\n",
      "...................................................Training Accuracy at epoch 13 is:  0.6069651741293532\n",
      "Validation Accuracy at epoch 13 is:  0.5123152709359606\n",
      "...................................................Training Accuracy at epoch 14 is:  0.5796019900497512\n",
      "Validation Accuracy at epoch 14 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 15 is:  0.6144278606965174\n",
      "Validation Accuracy at epoch 15 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 16 is:  0.6144278606965174\n",
      "Validation Accuracy at epoch 16 is:  0.5467980295566502\n",
      "...................................................Training Accuracy at epoch 17 is:  0.6019900497512438\n",
      "Validation Accuracy at epoch 17 is:  0.5467980295566502\n",
      "...................................................Training Accuracy at epoch 18 is:  0.6019900497512438\n",
      "Validation Accuracy at epoch 18 is:  0.541871921182266\n",
      "...................................................Training Accuracy at epoch 19 is:  0.6243781094527363\n",
      "Validation Accuracy at epoch 19 is:  0.541871921182266\n",
      "...................................................Training Accuracy at epoch 20 is:  0.5696517412935324\n",
      "Validation Accuracy at epoch 20 is:  0.5467980295566502\n",
      "...................................................Training Accuracy at epoch 21 is:  0.5696517412935324\n",
      "Validation Accuracy at epoch 21 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 22 is:  0.6243781094527363\n",
      "Validation Accuracy at epoch 22 is:  0.5467980295566502\n",
      "...................................................Training Accuracy at epoch 23 is:  0.6293532338308457\n",
      "Validation Accuracy at epoch 23 is:  0.541871921182266\n",
      "...................................................Training Accuracy at epoch 24 is:  0.5970149253731343\n",
      "Validation Accuracy at epoch 24 is:  0.5714285714285714\n",
      "...................................................Training Accuracy at epoch 25 is:  0.6293532338308457\n",
      "Validation Accuracy at epoch 25 is:  0.5911330049261084\n",
      "...................................................Training Accuracy at epoch 26 is:  0.5895522388059702\n",
      "Validation Accuracy at epoch 26 is:  0.5517241379310345\n",
      "...................................................Training Accuracy at epoch 27 is:  0.6293532338308457\n",
      "Validation Accuracy at epoch 27 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 28 is:  0.6144278606965174\n",
      "Validation Accuracy at epoch 28 is:  0.5665024630541872\n",
      "...................................................Training Accuracy at epoch 29 is:  0.6069651741293532\n",
      "Validation Accuracy at epoch 29 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 30 is:  0.6044776119402985\n",
      "Validation Accuracy at epoch 30 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 31 is:  0.6268656716417911\n",
      "Validation Accuracy at epoch 31 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 32 is:  0.5621890547263682\n",
      "Validation Accuracy at epoch 32 is:  0.5862068965517241\n",
      "...................................................Training Accuracy at epoch 33 is:  0.5845771144278606\n",
      "Validation Accuracy at epoch 33 is:  0.5665024630541872\n",
      "...................................................Training Accuracy at epoch 34 is:  0.582089552238806\n",
      "Validation Accuracy at epoch 34 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 35 is:  0.6243781094527363\n",
      "Validation Accuracy at epoch 35 is:  0.5320197044334976\n",
      "...................................................Training Accuracy at epoch 36 is:  0.599502487562189\n",
      "Validation Accuracy at epoch 36 is:  0.5566502463054187\n",
      "...................................................Training Accuracy at epoch 37 is:  0.6144278606965174\n",
      "Validation Accuracy at epoch 37 is:  0.5615763546798029\n",
      "...................................................Training Accuracy at epoch 38 is:  0.6019900497512438\n",
      "Validation Accuracy at epoch 38 is:  0.5123152709359606\n",
      "...................................................Training Accuracy at epoch 39 is:  0.6144278606965174\n",
      "Validation Accuracy at epoch 39 is:  0.5467980295566502\n",
      "...................................................Training Accuracy at epoch 40 is:  0.6119402985074627\n",
      "Validation Accuracy at epoch 40 is:  0.5812807881773399\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)\n",
    "\n",
    "val_acc=[]\n",
    "loss_list=[]\n",
    "train_acc =[]\n",
    "for epoch in range(40):\n",
    "    loss_sublist = []\n",
    "    corr = 0\n",
    "    for x, y in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        _, yhat = torch.max(preds.data, 1)\n",
    "        corr += (yhat == y).sum().item()\n",
    "        print(\".\",end='',flush = True )\n",
    "    \n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    acc = corr/len(train_data)\n",
    "    print(\"Training Accuracy at epoch\",epoch+1,\"is: \",acc)\n",
    "    train_acc.append(acc)\n",
    "    \n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            model.eval()\n",
    "            x_test = x_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "            z = model(x_test)\n",
    "            _, yhat1 = torch.max(z.data, 1)\n",
    "            correct += (yhat1 == y_test).sum().item()\n",
    "    accuracy = correct / len(test_data)\n",
    "    print(\"Validation Accuracy at epoch\",epoch+1,\"is: \",accuracy)\n",
    "    val_acc.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9df43cbf-45bf-4873-ba3c-19fc5e33dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = test_data[0][0].to('cuda')\n",
    "t = t.unsqueeze(0)\n",
    "v = model\n",
    "from vit_pytorch.recorder import Recorder\n",
    "v = Recorder(v)\n",
    "#print(t.shape)\n",
    "\n",
    "# img = torch.randn(1, 3, 256, 256)\n",
    "preds, attns = v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2dbb1-2f65-45f7-bb42-5deb6a32e95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e08d223-e45d-4f09-9c07-8e337c43586e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(attns.shape)\n",
    "attns = attns.cpu()\n",
    "at = attns.numpy()\n",
    "at = at[:,1,2,:,:]\n",
    "at = at.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f947a0f-b040-4bc5-8483-1c4a44184a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e02cdfc-df67-4eb3-b669-d3c6846d4572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcd73fc7-1fa6-4b54-bccb-84da37a7b5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 6.9169592e-10, 2.9093907e-27, ..., 6.4895589e-10,\n",
       "        6.2268285e-08, 4.6734217e-30],\n",
       "       [0.0000000e+00, 1.8764418e-07, 1.8709697e-19, ..., 1.7088848e-07,\n",
       "        1.5214168e-06, 3.6109948e-22],\n",
       "       [0.0000000e+00, 1.9718716e-07, 1.7371355e-19, ..., 1.7993590e-07,\n",
       "        1.7254114e-06, 4.4750663e-22],\n",
       "       ...,\n",
       "       [0.0000000e+00, 1.8706757e-07, 1.8705786e-19, ..., 1.7034257e-07,\n",
       "        1.5091005e-06, 3.5675261e-22],\n",
       "       [0.0000000e+00, 1.7846708e-07, 1.7059513e-19, ..., 1.6255068e-07,\n",
       "        1.4429299e-06, 3.0171357e-22],\n",
       "       [0.0000000e+00, 5.5549933e-08, 4.2318762e-21, ..., 5.0812403e-08,\n",
       "        7.0658916e-07, 6.7907119e-24]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69ea0b-0496-4f53-b72a-e955dbc08a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
